{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d53da3f",
   "metadata": {},
   "source": [
    "## LLM Inference\n",
    "\n",
    "Cells below show how to use the OllamaClient and the HFClient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import OllamaClient\n",
    "client = OllamaClient(base_url=\"http://localhost:11434\")\n",
    "model=\"qwen2.5:0.5b-instruct\"\n",
    "client.download_model(model=model)\n",
    "print(model)\n",
    "client.warmup_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80753458",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.generate(model=model, prompt=\"What is the capital of France?\", max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c63bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trl, transformers, accelerate, torch, sys\n",
    "print(\"trl version:\", trl.__version__)\n",
    "print(\"transformers version:\", transformers.__version__)\n",
    "print(\"accelerate version:\", accelerate.__version__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"sys version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941213e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune import PRewriteTrainer\n",
    "\n",
    "tok, model, ref_model = PRewriteTrainer.load_from_hf(\"gpt2\")\n",
    "    # model_id=\"Qwen/Qwen2.5-0.5B-Instruct\")\n",
    "# print(f\"Model keys: {model.state_dict().keys()}\")\n",
    "print(model.base_model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune import PRewriteTrainer\n",
    "\n",
    "trainer = PRewriteTrainer(\n",
    "    # model_id=\"gpt2\",\n",
    "    # model_id=\"Qwen/Qwen2.5-0.5B-Instruct\", \n",
    "    model_id=\"gpt2\",\n",
    "    dataset=\"openai/gsm8k:main\",\n",
    "    task=\"math\",\n",
    "    evaluator_model=\"qwen2.5:0.5b-instruct\",\n",
    "    ollama=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23856fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46afe469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 01:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=-0.03685940305391947, metrics={'train_runtime': 77.7071, 'train_samples_per_second': 0.039, 'train_steps_per_second': 0.039, 'total_flos': 0.0, 'train_loss': -0.03685940305391947})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from trl import GRPOTrainer\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"trl-lib/tldr\", split=\"train\")\n",
    "\n",
    "# Select a smaller test dataset with 1 item\n",
    "small_dataset = dataset.select([0])\n",
    "\n",
    "# Dummy reward function: count the number of unique characters in the completions\n",
    "def reward_num_unique_chars(completions, **kwargs):\n",
    "    return [len(set(c)) for c in completions]\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=\"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    reward_funcs=reward_num_unique_chars,\n",
    "    train_dataset=small_dataset,  # Use the small dataset here\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84443576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs401r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
